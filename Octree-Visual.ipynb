{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5991bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0228abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function for creating unique id for each node\n",
    "\n",
    "node_ids = set()\n",
    "\n",
    "def generate_node_id(node_ids):\n",
    "    new_id = random.randint(1, 1e5)\n",
    "    while new_id in node_ids:\n",
    "        new_id = random.randint(1, 1e5)\n",
    "    node_ids.add(new_id)\n",
    "    return new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0f8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State capture per density_threshold\n",
    "\n",
    "# By capturing the tree structure at each threshold, \n",
    "# you can see how features like connected components emerge, evolve, and disappear.\n",
    "# This provides insights into the tree's resilience, adaptability, and the significance of its structural features.\n",
    "# In the case of tree data structure, there is no hole so only connected dots (B_0) is considered\n",
    "\n",
    "# Depth Threshold\n",
    "\n",
    "depth_threshold = 3\n",
    "\n",
    "# Degree/Density Threshold\n",
    "\n",
    "density_thresholds = list(range(0, 4097, 16)) # [0, 16, 32, ..., 4096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3410a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function\n",
    "\n",
    "def visualize_octree(data, source_id, depth, density_threshold, betti_0, octree):\n",
    "    # Base case\n",
    "    if depth == depth_threshold or len(data) == 0:\n",
    "        return betti_0, octree\n",
    "    \n",
    "    # Calculate the boundaries\n",
    "    min_x, max_x = data['X'].min(), data['X'].max()\n",
    "    min_y, max_y = data['Y'].min(), data['Y'].max()\n",
    "    min_z, max_z = data['Z'].min(), data['Z'].max()\n",
    "\n",
    "    # Calculate midpoints\n",
    "    mid_x = (max_x + min_x) / 2\n",
    "    mid_y = (max_y + min_y) / 2\n",
    "    mid_z = (max_z + min_z) / 2\n",
    "\n",
    "    # The eight octants in 3D space\n",
    "    subdivisions = [\n",
    "        (data['X'] <= mid_x) & (data['Y'] <= mid_y) & (data['Z'] <= mid_z),\n",
    "        (data['X'] <= mid_x) & (data['Y'] <= mid_y) & (data['Z'] > mid_z),\n",
    "        (data['X'] <= mid_x) & (data['Y'] > mid_y) & (data['Z'] <= mid_z),\n",
    "        (data['X'] <= mid_x) & (data['Y'] > mid_y) & (data['Z'] > mid_z),\n",
    "        (data['X'] > mid_x) & (data['Y'] <= mid_y) & (data['Z'] <= mid_z),\n",
    "        (data['X'] > mid_x) & (data['Y'] <= mid_y) & (data['Z'] > mid_z),\n",
    "        (data['X'] > mid_x) & (data['Y'] > mid_y) & (data['Z'] <= mid_z),\n",
    "        (data['X'] > mid_x) & (data['Y'] > mid_y) & (data['Z'] > mid_z),\n",
    "    ]\n",
    "\n",
    "    # We are reaching further depth\n",
    "    depth += 1\n",
    "\n",
    "    for subdivision in subdivisions:\n",
    "        filtered_data = data[subdivision]\n",
    "        num_points_in_box = len(filtered_data)\n",
    "        \n",
    "        target_id = generate_node_id(node_ids)\n",
    "        \n",
    "        # Create box to hold each piece of data\n",
    "        box = [num_points_in_box, depth, source_id, target_id]\n",
    "        \n",
    "        # Store box info\n",
    "        if num_points_in_box > density_threshold:\n",
    "            octree.append(box)\n",
    "            betti_0, octree = visualize_octree(filtered_data, target_id, depth, density_threshold, betti_0, octree)\n",
    "        else:\n",
    "            betti_0 += 1\n",
    "\n",
    "    return betti_0, octree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa9b956",
   "metadata": {},
   "source": [
    "### $Betti_0$ - Why Do We Need to Examinine It?\n",
    "\n",
    "**Why examine change in $Betti_0$ with across density thresholds?**\n",
    "\n",
    "1. Analyze how tree data structure's topplogy evolves as a condition (i.e., density thresholds) is applied \n",
    "\n",
    "2. Understand the shape of the input data across scales - provides insights into the data structure's resilience, adaptability, and the significance of its structural features\n",
    "\n",
    "3. Why only $Betti_0$ is examined - tree data structures don't create loop\n",
    "\n",
    "4. Why density thresholds? - maybe to provide insights to customize tree data structure (e.g., the greater the density threshold the less data a tree data structure stores yet the faster that data structure is created; the problem is - does it preserve the original features of the input data?)\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "1. Visualize which features of the input data are robust across a range of conditions (i.e., different density thresholds)\n",
    "\n",
    "2. Understand how well a tree structure adapts to varying densities\n",
    "\n",
    "3. Build Speed across Density Thresholds (Zhonghao)\n",
    "\n",
    "4. Octree vs. K-D Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c40a2",
   "metadata": {},
   "source": [
    "### $Betti_0$ Change in House Point Clouds Across Octree Density Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f614bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data for House Random\n",
    "\n",
    "data_random = pd.read_csv('data/House/csv/random/house_random.csv', sep=',')[['X', 'Y', 'Z']]\n",
    "house_random_betti_0s = []\n",
    "\n",
    "for density_threshold in density_thresholds:\n",
    "    initial_source_id = 0 # the root\n",
    "    initial_depth = 0 # the root is at depth 0\n",
    "    initial_betti_0 = 1 # the root itself\n",
    "    octree = [] # for storing the whole octree\n",
    "    betti_0, octree = visualize_octree(data_random, \\\n",
    "                                       initial_source_id, \\\n",
    "                                       initial_depth, \\\n",
    "                                       density_threshold, \\\n",
    "                                       initial_betti_0, \\\n",
    "                                       octree)\n",
    "    house_random_betti_0s.append(betti_0)\n",
    "\n",
    "# Read the data for House Spatial\n",
    "\n",
    "data_spatial = pd.read_csv('data/House/csv/spatial/house_spatial.csv', sep=',')[['X', 'Y', 'Z']]\n",
    "house_spatial_betti_0s = []\n",
    "\n",
    "for density_threshold in density_thresholds:\n",
    "    initial_source_id = 0 # the root\n",
    "    initial_depth = 0 # the root is at depth 0\n",
    "    initial_betti_0 = 1 # the root itself\n",
    "    octree = [] # for storing the whole octree\n",
    "    betti_0, octree = visualize_octree(data_spatial, \\\n",
    "                                       initial_source_id, \\\n",
    "                                       initial_depth, \\\n",
    "                                       density_threshold, \\\n",
    "                                       initial_betti_0, \\\n",
    "                                       octree)\n",
    "    house_spatial_betti_0s.append(betti_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e1788",
   "metadata": {},
   "source": [
    "### Variances of Among the Two Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7509f16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198.955623855017 2093.068085815078\n"
     ]
    }
   ],
   "source": [
    "var_house_random = np.var(np.array(house_random_betti_0s))\n",
    "var_house_spatial = np.var(np.array(house_spatial_betti_0s))\n",
    "\n",
    "print(var_house_random, var_house_spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f5295",
   "metadata": {},
   "source": [
    "### Wasserstein Distance Between the Two Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e05fb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.385214007782104\n"
     ]
    }
   ],
   "source": [
    "was_dis_house = wasserstein_distance(house_random_betti_0s, house_spatial_betti_0s)\n",
    "print(was_dis_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5f7bb",
   "metadata": {},
   "source": [
    "### $Betti_0$ Change in Tree Point Clouds Across Octree Density Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1350df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data for Tree Random\n",
    "\n",
    "data_random = pd.read_csv('data/Tree/csv/random/tree_random.csv', sep=',')[['X', 'Y', 'Z']]\n",
    "tree_random_betti_0s = []\n",
    "\n",
    "for density_threshold in density_thresholds:\n",
    "    initial_source_id = 0 # the root\n",
    "    initial_depth = 0 # the root is at depth 0\n",
    "    initial_betti_0 = 1 # the root itself\n",
    "    octree = [] # for storing the whole octree\n",
    "    betti_0, octree = visualize_octree(data_random, \\\n",
    "                                       initial_source_id, \\\n",
    "                                       initial_depth, \\\n",
    "                                       density_threshold, \\\n",
    "                                       initial_betti_0, \\\n",
    "                                       octree)\n",
    "    tree_random_betti_0s.append(betti_0)\n",
    "\n",
    "# Read the data for Tree Spatial\n",
    "\n",
    "data_spatial = pd.read_csv('data/Tree/csv/spatial/tree_spatial.csv', sep=',')[['X', 'Y', 'Z']]\n",
    "tree_spatial_betti_0s = []\n",
    "\n",
    "for density_threshold in density_thresholds:\n",
    "    initial_source_id = 0 # the root\n",
    "    initial_depth = 0 # the root is at depth 0\n",
    "    initial_betti_0 = 1 # the root itself\n",
    "    octree = [] # for storing the whole octree\n",
    "    betti_0, octree = visualize_octree(data_spatial, \\\n",
    "                                       initial_source_id, \\\n",
    "                                       initial_depth, \\\n",
    "                                       density_threshold, \\\n",
    "                                       initial_betti_0, \\\n",
    "                                       octree)\n",
    "    tree_spatial_betti_0s.append(betti_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43807122",
   "metadata": {},
   "source": [
    "### Variances of Among the Two Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f3fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1757.931293433663 1733.9757452800188\n"
     ]
    }
   ],
   "source": [
    "var_tree_random = np.var(np.array(tree_random_betti_0s))\n",
    "var_tree_spatial = np.var(np.array(tree_spatial_betti_0s))\n",
    "\n",
    "print(var_tree_random, var_tree_spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830e8a6",
   "metadata": {},
   "source": [
    "### Wasserstein Distance Between the Two Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e5a4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9066147859922182\n"
     ]
    }
   ],
   "source": [
    "was_dis_tree = wasserstein_distance(tree_random_betti_0s, tree_spatial_betti_0s)\n",
    "print(was_dis_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b66f4",
   "metadata": {},
   "source": [
    "### $Betti_0$ Change in Light Pole Point Clouds Across Octree Density Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aaecace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data for Light Pole Random\n",
    "\n",
    "data_random = pd.read_csv('data/LightPole/csv/random/lightpole_random.csv', sep=',')[['X', 'Y', 'Z']]\n",
    "lightpole_random_betti_0s = []\n",
    "\n",
    "for density_threshold in density_thresholds:\n",
    "    initial_source_id = 0 # the root\n",
    "    initial_depth = 0 # the root is at depth 0\n",
    "    initial_betti_0 = 1 # the root itself\n",
    "    oclightpole = [] # for storing the whole oclightpole\n",
    "    betti_0, oclightpole = visualize_octree(data_random, \\\n",
    "                                       initial_source_id, \\\n",
    "                                       initial_depth, \\\n",
    "                                       density_threshold, \\\n",
    "                                       initial_betti_0, \\\n",
    "                                       oclightpole)\n",
    "    lightpole_random_betti_0s.append(betti_0)\n",
    "\n",
    "# Read the data for Light Pole Spatial\n",
    "\n",
    "data_spatial = pd.read_csv('data/LightPole/csv/spatial/lightpole_spatial.csv', sep=',')[['X', 'Y', 'Z']]\n",
    "lightpole_spatial_betti_0s = []\n",
    "\n",
    "for density_threshold in density_thresholds:\n",
    "    initial_source_id = 0 # the root\n",
    "    initial_depth = 0 # the root is at depth 0\n",
    "    initial_betti_0 = 1 # the root itself\n",
    "    oclightpole = [] # for storing the whole oclightpole\n",
    "    betti_0, oclightpole = visualize_octree(data_spatial, \\\n",
    "                                       initial_source_id, \\\n",
    "                                       initial_depth, \\\n",
    "                                       density_threshold, \\\n",
    "                                       initial_betti_0, \\\n",
    "                                       oclightpole)\n",
    "    lightpole_spatial_betti_0s.append(betti_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38a126",
   "metadata": {},
   "source": [
    "### Variances of Among the Two Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec7c7b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880.8675680176841 979.5818256143164\n"
     ]
    }
   ],
   "source": [
    "var_lightpole_random = np.var(np.array(lightpole_random_betti_0s))\n",
    "var_lightpole_spatial = np.var(np.array(lightpole_spatial_betti_0s))\n",
    "\n",
    "print(var_lightpole_random, var_lightpole_spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a13703",
   "metadata": {},
   "source": [
    "### Wasserstein Distance Between the Two Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d88768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8754863813229592\n"
     ]
    }
   ],
   "source": [
    "was_dis_lightpole = wasserstein_distance(lightpole_random_betti_0s, lightpole_spatial_betti_0s)\n",
    "print(was_dis_lightpole)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59388845",
   "metadata": {},
   "source": [
    "### Visualizations of $Betti_0$ Change For All Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f672f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the global min and max y-values\n",
    "\n",
    "min_val = min([min(house_random_betti_0s), min(house_spatial_betti_0s), \\\n",
    "           min(tree_random_betti_0s), min(tree_spatial_betti_0s), \\\n",
    "           min(lightpole_random_betti_0s), min(lightpole_random_betti_0s)])\n",
    "\n",
    "max_val = max([max(house_random_betti_0s), max(house_spatial_betti_0s), \\\n",
    "           max(tree_random_betti_0s), max(tree_spatial_betti_0s), \\\n",
    "           max(lightpole_random_betti_0s), max(lightpole_random_betti_0s)])\n",
    "\n",
    "# Create plot\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(11, 15))\n",
    "\n",
    "# Plot for House Random\n",
    "axs[0,0].plot(density_thresholds, house_random_betti_0s)\n",
    "axs[0,0].set_xlabel('Density Thresholds')\n",
    "axs[0,0].set_ylabel('Betti-0 Counts')\n",
    "axs[0,0].set_ylim(min_val, max_val)\n",
    "axs[0,0].set_title('Data: Randomly Reduced House Data')\n",
    "\n",
    "# Plot for House Spatial\n",
    "axs[0,1].plot(density_thresholds, house_spatial_betti_0s)\n",
    "axs[0,1].set_xlabel('Density Thresholds')\n",
    "axs[0,1].set_ylabel('Betti-0 Counts')\n",
    "axs[0,1].set_ylim(min_val, max_val)\n",
    "axs[0,1].set_title('Data: Spatially Reduced House Data')\n",
    "\n",
    "# Plot for Tree Random\n",
    "axs[1,0].plot(density_thresholds, tree_random_betti_0s)\n",
    "axs[1,0].set_xlabel('Density Thresholds')\n",
    "axs[1,0].set_ylabel('Betti-0 Counts')\n",
    "axs[1,0].set_ylim(min_val, max_val)\n",
    "axs[1,0].set_title('Data: Randomly Reduced Tree Data')\n",
    "\n",
    "# Plot for Tree Spatial\n",
    "axs[1,1].plot(density_thresholds, tree_spatial_betti_0s)\n",
    "axs[1,1].set_xlabel('Density Thresholds')\n",
    "axs[1,1].set_ylabel('Betti-0 Counts')\n",
    "axs[1,1].set_ylim(min_val, max_val)\n",
    "axs[1,1].set_title('Data: Spatially Reduced Tree Data')\n",
    "\n",
    "# Plot for Light Pole Random\n",
    "axs[2,0].plot(density_thresholds, lightpole_random_betti_0s)\n",
    "axs[2,0].set_xlabel('Density Thresholds')\n",
    "axs[2,0].set_ylabel('Betti-0 Counts')\n",
    "axs[2,0].set_ylim(min_val, max_val)\n",
    "axs[2,0].set_title('Data: Randomly Reduced Light Pole Data')\n",
    "\n",
    "# Plot for Light Pole Spatial\n",
    "axs[2,1].plot(density_thresholds, lightpole_spatial_betti_0s)\n",
    "axs[2,1].set_xlabel('Density Thresholds')\n",
    "axs[2,1].set_ylabel('Betti-0 Counts')\n",
    "axs[2,1].set_ylim(min_val, max_val)\n",
    "axs[2,1].set_title('Data: Spatially Reduced Light Pole Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f29bb",
   "metadata": {},
   "source": [
    "### Comparison Among Z-Score Normalized Varainces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b860cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54136592 1.46067405 0.71025698 0.65661724 1.25360854 1.03257383]\n"
     ]
    }
   ],
   "source": [
    "var = np.array([var_house_random, var_house_spatial, \\\n",
    "                var_tree_random, var_tree_spatial, \\\n",
    "                var_lightpole_random, var_lightpole_spatial])\n",
    "var_normal = (var - np.mean(var)) / np.std(var)\n",
    "\n",
    "print(abs(var_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9c924",
   "metadata": {},
   "source": [
    "| Input Data |Variances|\n",
    "| -| - |\n",
    "| House (Random)  | 0.54136592  |\n",
    "| House (Spatial) | 1.46067405  |\n",
    "| Tree (Random) | 0.71025698  |\n",
    "| Tree (Spatial) | 0.65661724  |\n",
    "| Light Pole (Random) | 1.25360854  |\n",
    "| Light Pole (Spatial) | 1.03257383  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f0bed",
   "metadata": {},
   "source": [
    "### Comparison Among Z-Score Normalized Wasserstein Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e2b09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.39466675 0.9002582  0.49440855]\n"
     ]
    }
   ],
   "source": [
    "was_dis = np.array([was_dis_house, was_dis_tree, was_dis_lightpole])\n",
    "\n",
    "was_dis_normal = (was_dis - np.mean(was_dis)) / np.std(was_dis)\n",
    "\n",
    "print(abs(was_dis_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6bd9d",
   "metadata": {},
   "source": [
    "| Input Data |Normalized Wasserstein Distance|\n",
    "| -| - |\n",
    "| House | 1.39466675  |\n",
    "| Tree | 0.9002582  |\n",
    "| Light Pole | 0.49440855 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0439737",
   "metadata": {},
   "source": [
    "# What do these numbers potentially show?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8053ecd",
   "metadata": {},
   "source": [
    "1. Comparatively Greater Variance difference between House(Random) and House(Spatial) data\n",
    "\n",
    "2. Subsample choice matters for reducing House Data\n",
    "\n",
    "3. **Spatial subsampling** preserves more of the original house structure.<br>That being said: Spatial subsampling method **usually recommended** for storing house point cloud data **if one wants to presserve a very well structured house point cloud**. Please be awared that the spatial subsampling method is **slow**. \n",
    "\n",
    "4. Interestingly, random and spatial subsampling methods works comparatively well for both Tree (comparatively ill structured) and Light Pole (comparatively well structured) data. That being said: **random subsampling method** in these two cases is **usually recommended** since it is a lot faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605a7de",
   "metadata": {},
   "source": [
    "# What do these numbers further show?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f828405",
   "metadata": {},
   "source": [
    "**House**\n",
    "\n",
    "1. Comparatively greater variance difference among the two house topo graphs. \n",
    "\n",
    "2. Subsample choice usually matters for representing House Data - because we can't control how random subsampling method may sometimes distord the original structure.\n",
    "\n",
    "3. Spatial Subsampling method usually preserves more of the original house structure, although it is slower.\n",
    "\n",
    "4. Wasserstein distance between the two topological graphs is the largest - probably because how the two subsampling methods result in very different structured data, so they aren't similar. \n",
    "\n",
    "5. Which part of the house got discarded at the early stage when density threshold is low? The non-roof part. Why? Not enough points in most of the octants to pass the density threshold. So what? If one wants to search for any point near the base of the house, one would not find them if the density threshold is set to be too high and if the house structure aren't preserved well.\n",
    "\n",
    "\n",
    "**Light Pole & Tree**\n",
    "\n",
    "1. Wasserstein distance between of the two light pole point cloud data is the shortest. Why? The very \"obvious\" and organized geometry of light poles makes their structure hard to get destroyed in either random or spatial subsampling.\n",
    "\n",
    "2. The Wasserstein distance between two tree data sets is comparatively long (2 times of that of light pole data). Why? Not all leaf areas have an equal density of points, so some leaf areas are discarded by the density threshold earlier, and that makes a big(?) difference between storing two kinds of tree data in an octree.\n",
    "\n",
    "3. However, very interestingly, if one takes a look at the vidualizations of the two tree point cloud, that produced by random subsampling method looks more \"tree-like\".\n",
    "\n",
    "4. Due to the slender feature of the light pole in addition to the inclusion of the base/ground part in its point cloud data file, more points are concentrated in fewer octants of the octree. So, a larger portion of the point cloud that construct the significant part of the light pole (i.e., what construct its slender feature) are going to get destroyed first with a relatively high density threshold and with a base/ground area in the input point cloud file. \n",
    "\n",
    "5. Which part of the light pole or tree got discarded at the early stage when density threshold is low? The foilage part (tree) and the pole part (lighe pole). Why? Low density. So what? Unfortunately octree gives equal attention to all of its octant without considering the actual density of those octants, so one has to be aware that if the density threshold is too high for storing any point cloud object with one part that is obviously less dense than the others, then that part with less density is going to get discarded first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af157f72",
   "metadata": {},
   "source": [
    "### Export Files for Visualization in Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d65e71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# octree_df = pd.DataFrame(octree, columns=['Degree', 'Depth', 'Source', 'Target'])\n",
    "\n",
    "# # Edge\n",
    "# # Source,Target,Type\n",
    "\n",
    "# octree_df_edge = octree_df[['Source', 'Target']].copy()\n",
    "# octree_df_edge['Type'] = 'Directed'\n",
    "\n",
    "# # Node\n",
    "# # Id,Degree(num_point),Depth\n",
    "\n",
    "# octree_df_node = octree_df[['Target', 'Degree', 'Depth']]\n",
    "# octree_df_node = octree_df_node.rename(columns={'Target': 'Id'})\n",
    "# octree_df_node.loc[len(octree_df_node)] = {'Id': 0, 'Degree': 4096, 'Depth': 0} # append root node\n",
    "\n",
    "# # export CSV\n",
    "\n",
    "# octree_df_edge.to_csv('edge.csv', index = False)\n",
    "# octree_df_node.to_csv('node.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
